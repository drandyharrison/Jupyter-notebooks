{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Example\n",
    "Using the Pima Indian Diabetes dataset\n",
    "https://www.kaggle.com/uciml/pima-indians-diabetes-database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Manipulation packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Machiene Learning packages\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#viz packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names=['pregnant','glucose','bp','skin','insulin','bmi','pedigree','age','label']\n",
    "#load in csv\n",
    "\n",
    "pima=pd.read_csv(\"diabetes.csv\", header=None, skiprows=[0], names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Exploration & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# rows = {}, # columns = {}'.format(pima.shape[0], pima.shape[1]))\n",
    "pima.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there any missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pima.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace Missing Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace categorical missing with missing category \n",
    "#df[df.columns[df.dtypes == 'object']] = df[df.columns[df.dtypes == 'object']].fillna(value='missing')\n",
    "\n",
    "#Replace with zero if  missing means zero\n",
    "#df['xxx'].fillna(0,inplace=True)\n",
    "\n",
    "#Replace remaining numerical missings with median\n",
    "#df.fillna(df.median(), inplace=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Detection & Removal\n",
    "\n",
    "For continous numeric variables, it is worth excluding outlying data points that might otherwise skew the learning of our model later.\n",
    "\n",
    "A standard way to do this is to use the 6-sigma idea: for a normal distribution (assumption!), 99% of the data should be within +- 3 standard deviations. So anything outside of 6 deviations should definitely be an outlier.\n",
    "\n",
    "<img src=\"normal_distribution.PNG\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find numeric values\n",
    "numeric_cols = pima.columns[pima.dtypes != 'object'].tolist()\n",
    "\n",
    "# Don't consider binary variables\n",
    "for col in numeric_cols:\n",
    "    if (pima[col].min() == 0) and (pima[col].max() == 1):\n",
    "        numeric_cols.remove(col)\n",
    "\n",
    "# Calculate the means and standard deviations\n",
    "means = pima[numeric_cols].mean()\n",
    "stddevs = pima[numeric_cols].std()\n",
    "\n",
    "# Find out how many values are outliers\n",
    "sigma = 6\n",
    "outlier_percs = []\n",
    "contains_outlier_any_col = np.zeros([len(pima), ]).astype(bool)\n",
    "for col in numeric_cols:\n",
    "    outlier = (pima[col] > means[col] + sigma * stddevs[col]) | (pima[col] < means[col] - sigma * stddevs[col])\n",
    "    contains_outlier_any_col = contains_outlier_any_col | outlier\n",
    "    outlier_percs.append(100 * sum(outlier) / len(outlier))\n",
    "    \n",
    "# Assemble results into a dataframe\n",
    "outliers_df = pd.DataFrame(\n",
    "    {'Column': numeric_cols, 'Outlier percentage': outlier_percs}\n",
    ").sort_values(by='Outlier percentage', ascending=False)\n",
    "\n",
    "# Total percentage of outliers\n",
    "print('% of rows with an outlier = {:.2f}%'.format(100 * sum(contains_outlier_any_col) / len(contains_outlier_any_col)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima = pima[~contains_outlier_any_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#is age positive?\n",
    "\n",
    "def age_positive(ls):\n",
    "    for i in ls:\n",
    "        if i < 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "age_positive(pima.age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going to try and predict whether someone has diabetes based on this data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split out target and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['pregnant', 'insulin', 'bmi', 'age','glucose','bp','pedigree']\n",
    "X = pima[feature_cols] # Features\n",
    "y = pima.label # Target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=0,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check target distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=[5, 5])\n",
    "counts = 100 * y_train.value_counts() / len(y_train)\n",
    "sns.barplot(x=counts.index, y=counts, ax=ax)\n",
    "ax.set_xlabel('Label')\n",
    "ax.set_ylabel('Proportion of data (%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class count\n",
    "count_class_0, count_class_1 = y_train.value_counts()\n",
    "\n",
    "# Divide by class\n",
    "y_class_0 = y_train[y_train== 0]\n",
    "y_class_1 = y_train[y_train== 1]\n",
    "\n",
    "#undersample 0\n",
    "y_class_0_under = y_class_0.sample(count_class_1)\n",
    "\n",
    "y_train_sampled=pd.concat([y_class_0_under, y_class_1], axis=0)\n",
    "\n",
    "#plot undersampled target\n",
    "fig, ax = plt.subplots(1, 1, figsize=[5, 5])\n",
    "counts = 100 * y_train_sampled.value_counts() / len(y_train_sampled)\n",
    "sns.barplot(x=counts.index, y=counts, ax=ax)\n",
    "ax.set_xlabel('Label')\n",
    "ax.set_ylabel('Proportion of data (%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Development and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the model \n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# fit the model with train data\n",
    "logreg.fit(X_train,y_train)\n",
    "\n",
    "#apply model to test data\n",
    "y_pred=logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model evaluation using Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise Confusion Matrx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=[0,1] # name  of classes\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision: how often the prediction is correct\n",
    "\n",
    "Recall: what proportion of observations have been correctly assigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = logreg.predict_proba(X_test)[::,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logreg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients_df = pd.DataFrame({'Feature': X_test.columns, 'Coefficient': logreg.coef_[0]})\n",
    "coefficients_df['Coefficient magnitude'] = coefficients_df['Coefficient'].abs()\n",
    "top_10 = coefficients_df.sort_values(by='Coefficient magnitude', ascending=False)[:10]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=[6, 7])\n",
    "sns.barplot(x=top_10['Coefficient'], y=top_10['Feature'])\n",
    "ax.set_title('Top 10 most important features')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
